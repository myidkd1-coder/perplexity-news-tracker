# Advantest ramps AI chip testing capacity as demand surges across hyperscalers and chipmakers

**Category:** Technology
**Source:** [https://techstartups.com/2026/01/28/top-tech-news-today-january-28-2026/](https://techstartups.com/2026/01/28/top-tech-news-today-january-28-2026/)
**Publisher:** Tech Startups
**Authors:** Nickie Louise
**Published:** January 28, 2026
**Scraped (UTC):** 2026-01-28T18:38:08+00:00

![Article Image](https://techstartups.com/wp-content/uploads/2020/08/Amazon.jpg)

## Summary
Advantest is accelerating production of semiconductor test equipment due to surging AI chip demand, validating high-performance GPUs and accelerators amid supply chain pressures. This expansion signals ongoing acceleration in AI infrastructure buildout.

## Full Article
It’s Wednesday, January 28, 2026, and here are the top tech stories making waves today — from AI and startups to regulation and Big Tech. Today’s technology landscape reflects a widening divide between those building the infrastructure of the AI era and those adapting to it.

From record-breaking demand for AI chips and data center capacity to tightening regulation around search, platforms, and generative models, the past 24 hours delivered signals that the next phase of tech is about control, scale, and execution. Below are 15 stories shaping how capital, compute, and policy collide across AI, Big Tech, cybersecurity, startups, and frontier technologies worldwide.

Here are the top 15 technology news stories shaping the global ecosystem today.

Technology News Today

Advantest ramps AI chip testing capacity as demand surges across hyperscalers and chipmakers

Advantest says it is accelerating production capacity for its semiconductor test equipment as AI spending continues to tighten the supply chain for critical manufacturing steps. The company’s testers are used to validate high-performance chips before they ship, and that workload is rising as advanced GPUs and AI accelerators move into faster release cycles and larger volumes.

Why this matters is simple: AI infrastructure is not only about Nvidia-style compute. It also depends on the less glamorous chokepoints, like testers, tools, and packaging, that determine how quickly the industry can turn new designs into reliable hardware at scale. When test capacity is constrained, it can delay launches, increase costs, and widen the gap between leaders and everyone else. The move also signals confidence that AI demand is not a one-quarter spike but a multi-year buildout.

Why It Matters: Test equipment is a quiet bottleneck for AI chips, and Advantest’s expanding capacity is a signal that the AI buildout is still accelerating.

Source: Bloomberg.

ASML posts record 2025 profit on AI-driven demand, but plans 1,700 job cuts

ASML made record $11.5 billion profit in 2025, pointing to strong AI-related demand and long-term customer confidence in capacity planning. At the same time, the company said it will cut roughly 1,700 jobs, framing it as a restructuring aimed at improving efficiency and sharpening focus on engineering and innovation.

For the broader ecosystem, ASML’s numbers function as a real-world proxy for how deep the AI capex cycle runs. Its lithography systems sit at the center of advanced chip manufacturing, meaning orders and guidance tend to reflect what chipmakers expect demand to look like two or three years out. The layoffs add a second signal: even in a boom, the semiconductor supply chain is trying to manage cost, productivity, and execution risk as the industry pushes into more complex manufacturing nodes and tighter export controls.

Why It Matters: ASML’s results are a read-through on the AI chip cycle, and the job cuts show even boom-era leaders are optimizing hard.

Source: AP News.

China clears Nvidia H200 imports for ByteDance, Alibaba, and Tencent, reshaping the AI chip race

China has reportedly approved major tech companies to buy large volumes of Nvidia’s H200 AI chips, reducing uncertainty for Chinese firms trying to scale frontier model training and inference. The approvals matter because the H200 is materially more capable than many alternatives, and because the process signals how China may balance AI competitiveness with domestic semiconductor ambitions.

This development lands at the intersection of geopolitics and compute economics. If Chinese platform companies can secure meaningful quantities of high-end accelerators, it can compress training timelines, lower per-token costs at scale, and keep China’s consumer and enterprise AI products closer to global performance frontiers. It also raises second-order questions: whether approvals come with conditions, whether local chip quotas will be attached, and how quickly supply can meet demand when global AI demand is already stretching the entire GPU pipeline.

Why It Matters: Access to top-tier GPUs is a competitive lever, and this move changes the near-term compute outlook for China’s biggest AI players.

Source: South China Morning Post.

SoftBank nears talks to add $30B more into OpenAI, signaling a new phase of mega-round AI financing

SoftBank is reportedly in discussions to invest up to $30 billion more in OpenAI as part of a much greater capital-raising effort. The scale alone is the headline, but the subtext is even bigger: frontier AI is converging on a financing model that looks more like infrastructure than traditional venture, with investors underwriting sustained compute burn, custom hardware, and long-term data center capacity.

For the startup ecosystem, mega-rounds at this level can shift talent flows, partnership dynamics, and pricing power across the entire stack. If OpenAI can secure more compute and distribution, it can draw more developers and enterprise budgets into its orbit. Meanwhile, competitors are forced to respond with their own funding, alliances, or differentiation strategies. It also adds pressure on governance and transparency, since capital at this scale is effectively a bet on how AI platforms will shape future labor, content, and enterprise software economics.

Why It Matters: Giant AI rounds are becoming the norm for frontier players, and they reshape the competitive map across models, talent, and infrastructure.

Source: The Financial Times.

UK competition watchdog weighs new rules for Google’s AI Overviews, turning search into a policy battleground

The UK’s competition regulator is preparing steps that could shape how Google’s AI-generated search summaries operate under local tech rules. The core issue is market power: when AI Overviews sit between publishers and users, regulators want to ensure competition remains real, not theoretical, and that rivals and content suppliers are not structurally disadvantaged.

This matters globally because search is quickly becoming an AI product, not just an index. If regulators set precedents on disclosure, ranking, sourcing, or opt-out controls, those expectations can ripple into other jurisdictions. For startups, the risk is dependency: many businesses still live or die on search visibility. If AI summaries reduce click-through, they can compress the economics of independent publishing and niche content sites. At the same time, clearer rules could create new opportunities for compliant AI search competitors and publisher tooling.

Why It Matters: As search becomes AI-driven, regulators are deciding what “fair” means for traffic, attribution, and competition.

Source: The Wall Street Journal.

Google explores letting publishers opt out of generative AI features in Search

Google says it is exploring updates that would allow sites to opt out specifically from Search generative AI features, rather than broader crawling or indexing controls. The shift is notable because publisher frustration has risen as AI summaries and answer features change user behavior and reduce the value of page visits, even when content is still used to generate answers.

The stakes are high for the open web. If opt-out controls are real, clear, and respected, it could reduce pressure for harsher regulation and lower the risk of a full-scale publisher backlash. If controls are limited or confusing, it could accelerate a move toward paywalls, licensing regimes, or closed content ecosystems that only large players can navigate. For startups building content businesses, this is existential: traffic volatility is already a defining risk, and AI presentation layers amplify it. The policy design of opt-out becomes a competitive factor, not a footnote.

Why It Matters: Publisher control over AI summaries could determine whether the open web remains economically viable in an AI-first search era.

Source: The Verge.

EU begins formal process to ensure Google shares Gemini AI access and search data under DMA

EU regulators have launched formal proceedings to clarify how Google should comply with the Digital Markets Act, focusing on access for rival search engines and AI developers. The aim is to define what “fair and non-discriminatory” access means in practice when the underlying assets are AI services, search ranking signals, and potentially valuable anonymized datasets.

This is a critical moment for European tech competition policy. If regulators succeed in forcing meaningful access, it could lower barriers for EU and global startups building search and AI products that currently struggle against platform advantages. If the resulting measures are narrow, slow, or easily gamed, it reinforces the idea that compliance becomes a box-checking exercise as the market continues to consolidate. Either way, it sets expectations for how AI services will be treated under competition law, which is increasingly the front line for platform regulation.

Why It Matters: The EU is trying to prevent AI and search from becoming even more winner-take-most, and the DMA is its main lever.

Source: AP News.

AI agents go mainstream with “Moltbot,” raising fresh security and permissioning risks

An AI agent called Moltbot is gaining attention for promising something users actually want: automation that connects to apps and performs tasks, not just chat. That popularity comes with a predictable downside. When agents integrate deeply with accounts, files, and workflows, the attack surface expands dramatically, especially if credentials, tokens, or broad permissions are involved.

For the ecosystem, this is a preview of the next platform shift. AI agents can become a new layer in the software distribution stack, potentially disintermediating apps and shifting where value accrues. But the trust model remains unsolved. Enterprises will demand audit logs, least-privilege permissioning, and strong identity controls. Consumers will need clearer safety defaults and better visibility into what an agent can access and what it actually did. Startups in agent tooling, identity, and endpoint security will benefit, because as agents become more capable, the cost of failures increases.

Why It Matters: AI agents can reshape software distribution, but weak permissioning could turn them into a security disaster.

Source: The Verge.

Nike investigates claim of 1.4TB data theft, highlighting shift toward “steal-and-leak” attacks

Nike is investigating claims by a threat group that it stole roughly 1.4 terabytes of internal data, reportedly related to design and manufacturing. Even if customer data is not involved, the incident underscores how modern breaches increasingly target operational and intellectual property assets, not just personal information.

The bigger story is the evolving ransomware playbook. More attackers are skipping encryption and going straight to extortion via data theft and leak pressure, which can be faster and harder to disrupt. For major brands, leaked product plans, supplier data, or internal documentation can cause competitive harm and operational disruption, even if consumers never see an immediate impact. For the tech ecosystem, it reinforces demand for stronger data classification, tighter access controls, and better monitoring of exfiltration patterns. AI also complicates the defense side by enabling faster social engineering and more scalable recon.

Why It Matters: Theft-first extortion is on the rise, and brand-scale companies are prime targets even when customer data is not the prize.

Source: TechRadar.

Okta-linked voice phishing campaign shows attackers scaling social engineering beyond email

Security researchers say a cybercrime group has claimed responsibility for voice phishing attacks connected to a broader social engineering campaign. Voice-based attacks can bypass traditional email defenses and exploit the human layer directly, especially when attackers combine scripted calls with stolen data and tailored prompts.

This matters because identity is now the core perimeter for cloud-first organizations. As more critical workflows run through SaaS and SSO, attackers focus on persuading humans to hand over credentials, approve MFA prompts, or install remote tools. AI lowers the cost of persuasion by improving scripts, personalizing content, and potentially enabling voice cloning. The practical outcome is that security programs must treat user verification as a product problem, not just a training issue. Better authentication flows, step-up verification, and privileged access controls become mandatory rather than best practices.

Why It Matters: Voice phishing is on the rise, and identity-centric attacks are becoming the fastest route into modern companies.

Source: Cybersecurity Dive.

Researchers demonstrate measurement-free logical quantum computation, reducing reliance on mid-circuit measurements

New research reports progress toward measurement-free, fault-tolerant logical operations, demonstrating a set of logical tools for universal quantum computation that reduces dependence on mid-circuit measurements and feed-forward controls. In practical terms, that targets a known engineering pain point: mid-circuit measurement workflows can be experimentally demanding, and avoiding them could simplify parts of quantum error correction.

The significance is not that quantum is suddenly ready for broad commercial use. It is that the field continues to accumulate credible engineering pathways that reduce complexity and improve scalability. If measurement-free approaches mature, they could influence hardware roadmaps for ion-trap and other architectures by shifting where precision and reliability requirements sit. For startups and national programs betting on quantum, progress at the error-correction layer is what ultimately determines whether quantum advantage becomes repeatable and economically meaningful, rather than a one-off lab result.

Why It Matters: Error correction is the gating factor for scalable quantum, and reducing measurement dependence could lower practical engineering hurdles.

Source: Nature (Quantum Information).

India’s spacetech “The Guild” raises $20.5M Series A to push deeper into space systems

India-based spacetech startup The Guild, formerly EtherealX, raised $20.5 million in a Series A round led by TDK Ventures and BIG Capital, with participation from multiple investors. The round is another marker of the expanding space economy beyond the US and Europe, with India steadily producing startups that combine hardware ambition with cost discipline and increasing access to launch and supply chains.

Why it matters is the downstream market. Spacetech is shifting from “build a rocket” narratives to services and infrastructure: payload deployment, communications, and hardware platforms that support commercial and government use cases. Capital flowing into these companies reflects demand for resilient networks, Earth observation, and next-generation systems that tie directly into defense, logistics, and climate intelligence. For founders, India’s space startup momentum also suggests a growing base of specialized talent and vendors that can sustain a long runway of product development.

Why It Matters: Global spacetech investment is broadening, and India is producing credible, well-funded builders in the space stack.

Source: YourStory.

European robotics and automation gets fresh capital as PROTOTYPE raises toward a €20M fund

Investor Andreas Klinger has raised a significant first close for a new fund targeting European founders working in robotics, automation, and AI. The fund plans to write early checks and reserve capital for follow-ons, focusing on physical-world businesses that typically require more patience and engineering depth than pure software plays.

This matters because robotics is moving from pilot projects to deployment economics. Warehouse automation, industrial inspection, and manufacturing autonomy are increasingly constrained by labor markets, resilience demands, and pressure to localize production. Europe has strengths in industrial engineering and applied research, but often struggles with scale capital and commercialization velocity. Targeted early-stage funds can help bridge that gap, creating a pipeline of companies that can later attract growth capital or strategic buyers. The broader point: physical AI is becoming a serious category again, not a cyclical side bet.

Why It Matters: Purpose-built capital for robotics can accelerate Europe’s physical AI pipeline and help deep tech scale into deployment.

Source: Sifted.

Amazon confirms another 16,000 corporate job cuts as Big Tech retools for AI-era efficiency

Amazon has confirmed an additional wave of corporate layoffs, totaling about 16,000 employees, extending a broader pattern of workforce reduction paired with organizational flattening. The rationale is less about immediate financial distress and more about reshaping execution: fewer layers, faster decision cycles, and reallocating spend toward priority areas where AI and automation can increase output per employee.

The broader significance is labor market signaling across tech. Big Tech is implicitly telling the market that “AI-first” is not only a product strategy but an operating model. That shifts expectations for headcount planning, corporate structure, and the types of roles that remain resilient. For startups, it increases talent availability in some functions while raising the bar for productivity and capital efficiency. It also affects the cloud ecosystem: as hyperscalers push AI infrastructure, they are simultaneously tightening internal costs, which could influence pricing discipline, procurement, and partner programs.

Why It Matters: Big Tech is restructuring around AI-driven productivity, and the ripple effects will hit hiring, org design, and startup talent markets.

Source: TechStartups via Amazon and CNBC.

Enterprise AI collides with insurance as Pace raises $10M, pointing to a new workflow battlefront

Pace has raised $10 million with a pitch that insurance is ripe for enterprise AI disruption, targeting workflows where underwriting, claims, and compliance create heavy operational drag. While many AI startups chase horizontal productivity, insurance is a high-friction vertical with large budgets, complex rules, and measurable outcomes, which makes it attractive if the product can survive procurement and regulatory scrutiny.

This matters because the next phase of enterprise AI adoption is moving from generic copilots to vertical systems that touch revenue and risk. Insurance is particularly sensitive: errors can create legal exposure, harm customers, and lead to regulatory consequences. That pressure can slow adoption, but it also creates moat potential for startups that can prove reliability, auditability, and integration depth. If companies like Pace succeed, it will serve as a template for “regulated-industry AI” more broadly, including finance, healthcare operations, and public-sector workflows.

Why It Matters: Vertical enterprise AI in regulated industries is where durable value can emerge, but it demands proof, controls, and credibility.

Source: Fortune.

Closing

That wraps today’s global tech briefing. As AI infrastructure scales, platforms face tighter scrutiny, and capital concentrates around execution, the signals are becoming clearer across the tech ecosystem. We’ll be tracking what moves next and what it means for builders, investors, and operators worldwide. Follow us on X @TheTechStartups for more real-time updates.

---

*Content scraped from public sources with attribution. Users assume all risk.*  
*Auto-generated by [Perplexity News Tracker](https://github.com/myidkd1-coder/perplexity-news-tracker)*