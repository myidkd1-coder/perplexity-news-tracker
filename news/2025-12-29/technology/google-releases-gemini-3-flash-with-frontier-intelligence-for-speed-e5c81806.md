# Google Releases Gemini 3 Flash with Frontier Intelligence for Speed

**Category:** Technology
**Source:** [https://blog.google/technology/ai/google-ai-updates-december-2025/](https://blog.google/technology/ai/google-ai-updates-december-2025/)
**Publisher:** Google Blog
**Authors:** Keyword Team, Molly Mchugh-Johnson, Jeff Dean, Demis Hassabis, James Manyika, Zahra Thompson, Mike Darling
**Published:** December 2025
**Scraped (UTC):** 2025-12-29T18:56:32+00:00

![Article Image](https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Dec_AI_Recap_ss.width-1300.png)

## Summary
Google launched Gemini 3 Flash, a fast AI model with advanced reasoning, now default in Gemini app and AI Mode in Search. It integrates across Google ecosystem, API Antigravity, and Vertex AI for global developers and enterprises.

## Full Article
We announced a new experiment to improve browsing and manage complex online tasks. We’ve all felt the friction of juggling dozens of tabs to research a topic or plan a trip. Enter Disco, a new browsing experience from Google Labs designed to tame that complexity. Disco features GenTabs, an experiment that proactively synthesizes your open tabs and chat history to build custom, interactive web applications — transforming a scattered browser session into a streamlined tool for getting things done.

We upgraded Gemini audio models for powerful voice interactions. The updated Gemini 2.5 Flash Native Audio is built to handle complex workflows and natural dialogue — meaning smoother conversations, higher accuracy and better responsiveness to instructions. It’s available now in AI Studio, Vertex AI, Gemini Live and, for the first time, Search Live. Plus, a new live speech translation beta in the Google Translate app brings live translation in 70+ languages directly to your headphones, preserving original intonation and pacing to unlock truly global communication.

We released a new Gemini Deep Research agent. We brought a more powerful Gemini Deep Research to developers through the Interactions API. Developers can now embed advanced research capabilities — like navigating complex topics and synthesizing findings — directly into their own applications using a Gemini API key from Google AI Studio. We’ve also open-sourced our new DeepSearchQA benchmark, offering a transparent way to test just how comprehensive and effective research agents can be on web tasks. Plus, we shared how developers are already building mobile-first solutions to address real-world problems, from AI assistants for the visually impaired to tools fostering autonomy for people with cognitive disabilities.

We released a new way for shoppers in the U.S. to use our virtual try-on tool. U.S. shoppers now have a more personalized way to find their next favorite outfit with our updated virtual try-on tool. Instead of needing a full-body photo, you can now upload a simple selfie and Nano Banana will generate a realistic, full-body digital version of you. Once you’ve selected your preferred studio-like image and clothing size, you can instantly see how you’d look in billions of products from our Shopping Graph.

---

*Content scraped from public sources with attribution. Users assume all risk.*  
*Auto-generated by [Perplexity News Tracker](https://github.com/myidkd1-coder/perplexity-news-tracker)*