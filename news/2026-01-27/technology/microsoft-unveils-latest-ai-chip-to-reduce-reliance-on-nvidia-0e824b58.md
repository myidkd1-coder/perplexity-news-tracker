# Microsoft Unveils Latest AI Chip to Reduce Reliance on Nvidia

**Category:** Technology
**Source:** [https://techxplore.com/news/2026-01-microsoft-unveils-latest-ai-chip.html](https://techxplore.com/news/2026-01-microsoft-unveils-latest-ai-chip.html)
**Publisher:** TechXplore
**Authors:** Matt Day
**Published:** January 2026
**Scraped (UTC):** 2026-01-27T12:51:46+00:00

![Article Image](https://scx2.b-cdn.net/gfx/news/hires/2025/ai-chip.jpg)

## Summary
Microsoft introduced a new AI chip designed to decrease dependence on Nvidia hardware, amid broader investments in AI infrastructure including $15B in startup Anthropic with Nvidia.

## Full Article
This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Credit: Pixabay/CC0 Public Domain

Microsoft Corp. is rolling out its second-generation artificial intelligence chip, the centerpiece of the company's push to power its services more efficiently and provide an alternative to Nvidia Corp. hardware.

The Maia 200 chip, which is being produced by Taiwan Semiconductor Manufacturing Co., is making its way to Microsoft data centers in Iowa, with deployments headed to the Phoenix area next. On Jan. 26, Microsoft invited developers to start using Maia's control software, but it's not clear when users of the company's Azure cloud service will be able to utilize servers running on the chip.

Some of the first units will go to Microsoft's superintelligence team, generating data to improve the next generation of AI models, cloud and AI chief Scott Guthrie said in a blog post. The chips will also be used to power the Copilot assistant for businesses and AI models, including OpenAI's latest, that Microsoft rents to cloud customers.

Microsoft's chip push started years after Amazon.com Inc. and Alphabet Inc.'s Google began designing their own chips. All three have a similar aim: cost-effective machines that can be seamlessly plugged into data centers and offer savings and other efficiencies to cloud customers. The high costs and short supply of the latest industry-leading chips from Nvidia has fueled a scramble to find alternative sources of computing power.

Microsoft says its chip delivers better performance on some AI tasks than comparable semiconductors from Google and Amazon Web Services. "Maia 200 is also the most efficient inference system Microsoft has ever deployed," Guthrie said, referring to the process of using AI models to generate responses to queries.

The company says it's already designing the chip's successor, the Maia 300. Microsoft has other options, should its internal efforts falter: As part of a deal with close partner OpenAI, the company has access to the ChatGPT maker's nascent chip designs.

Gartner analyst Chirag Dekate said the release of Maia 200 shows Microsoft is committed to its chipmaking effort. The growing energy needs of AI data centers and the lack of new power sources in many parts of the world make efficiency-focused projects like Maia more critical, he said.

"You don't engage in this sort of investment if you're just doing one or two stunt activities," Dekate said. "This is a multigeneration, strategic investment."

2026 Bloomberg L.P. Distributed by Tribune Content Agency, LLC.

---

*Content scraped from public sources with attribution. Users assume all risk.*  
*Auto-generated by [Perplexity News Tracker](https://github.com/myidkd1-coder/perplexity-news-tracker)*