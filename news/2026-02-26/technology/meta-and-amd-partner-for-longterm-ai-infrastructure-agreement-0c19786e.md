# Meta and AMD Partner for Longterm AI Infrastructure Agreement

**Category:** Technology
**Source:** [https://radicaldatascience.wordpress.com/2026/02/25/ai-news-briefs-bulletin-board-for-february-2026/](https://radicaldatascience.wordpress.com/2026/02/25/ai-news-briefs-bulletin-board-for-february-2026/)
**Publisher:** Radical Data Science
**Authors:** Daniel D. Gutierrez, Principal Analyst, Resident Data Scientist, About Daniel D. Gutierrez
**Published:** 2026-02-25
**Scraped (UTC):** 2026-02-26T02:04:40+00:00

![Article Image](https://radicaldatascience.wordpress.com/wp-content/uploads/2026/02/zvec_logo.png)

## Summary
Meta partners with AMD in a multi-year deal for up to 6GW of AMD Instinct GPUs to enhance AI infrastructure, with shipments starting late 2026 using Helios rack-scale architecture.

## Full Article
Welcome to the AI News Briefs Bulletin Board, a timely new channel bringing you the latest industry insights and perspectives surrounding the field of AI including deep learning, large language models, generative AI, and transformers. I am working tirelessly to dig up the most timely and curious tidbits underlying the day’s most popular technologies. I know this field is advancing rapidly and I want to bring you a regular resource to keep you informed and state-of-the-art. The news bites are constantly being added in reverse date order (most recent on top). With the bulletin board you can check back often to see what’s happening in our rapidly accelerating industry. Click HERE to check out previous “AI News Briefs” round-ups.

[2/25/2026] A Dream of Spring for Open-Weight LLMs: 10 Architectures from Jan-Feb 2026 – LLM industry luminary Sebastian Raschka provides a round up and comparison of 10 open-weight LLM releases in Spring 2026.

[2/25/2026] Meta and AMD Partner for Longterm AI Infrastructure Agreement – Meta has partnered with AMD in a multi-year agreement to enhance AI infrastructure with up to 6GW of AMD Instinct GPUs. This collaboration focuses on vertical integration across silicon, systems, and software, aligning roadmaps for scalable AI deployments. Shipments for the first GPU deployments will begin in late 2026, leveraging AMD’s Helios rack-scale architecture for enhanced compute power.

[2/25/2026] Qwen3.5-35B-A3B – Qwen3.5 integrates breakthroughs in multimodal learning, architectural efficiency, reinforcement learning scale, and global accessibility to deliver exceptional utility and performance. It features a unified vision-language foundation, an efficient hybrid architecture, scalable RL generalization, global linguisting coverage, and next-generation training infrastructure. Qwen3.5 natively supports context lengths of up to 262,144 tokens. This repository contains model weights and configuration files for the post-trained model in the Hugging Face Transformers format.

[2/25/2026] Citrini’s Scenario Is A Great But Deeply Flawed Thought Experiment – A recent viral essay about how AI’s bullishness could be bearish is full of flaws and just a work of speculative fiction. It posits that AI’s success will be bad for the economy rather than good. However, the reality is that the technology will create more opportunity in the market rather than destroy it. There may be transitional pains, but there probably won’t be any unsolvable problems.

[2/24/2026] Early in my career, I focused on model performance. Now I focus on clarity. If a stakeholder can’t understand what a model does, they won’t trust it—no matter the AUC. Transparency is not a feature. It’s a requirement.

[2/24/2026] The First Fully General Computer Action Model – FDM-1, a foundation model for computer use, efficiently trains on 11 million hours of video to autonomously handle tasks like CAD, driving, and fuzzing. Unlike traditional models that rely on expensive, limited annotation, FDM-1 uses a video encoder that compresses 2 hours of video into 1M tokens and predicts actions with inverse dynamics for scalable training. With enhanced context processing, FDM-1 showcases significant advancements in executing long-horizon tasks and exploring complex state trees in GUI environments.

[2/24/2026] AWS Launches Strands Labs to Give Developers a Sandbox for Autonomous AI – AWS Strands Labs is a new GitHub organization aimed at helping developers explore and experiment with cutting-edge AI techniques. It is currently available for three specific projects: robots, robots sim, and AI functions. AWS considers these areas the ones that most clearly reveal what changes when software becomes agentic. Strands Labs gives AWS and the broader community a dedicated space to experiment boldly.

[2/24/2026] GPT-5 Codex Ran a 25-Hour Coding Sprint – OpenAI described a long-horizon stress test where GPT-5.3-Codex, given a blank repository and full access, built a design tool over ~25 hours using ~13M tokens and producing ~30k lines of code.

[2/24/2026] Anthropic Reported Large-Scale Distillation Attempts – Anthropic accused DeepSeek, Moonshot AI, and MiniMax of creating over 24,000 fake accounts to generate roughly 16 million Claude interactions aimed at replicating its agentic reasoning, tool use, and coding capabilities.

[2/23/2026] AI startup’s custom chip gives AI a 10x speed boost – AI chip startup Taalas just emerged with HC1, a custom chip built to run a single AI model and nothing else — delivering responses roughly 100x faster than today’s standard hardware and 10x the SOTA for extreme speed in outputs.

Key details:

Taalas’ first chip permanently embeds Meta’s Llama 3.1 8B model into the hardware rather than running it as software on general-purpose chips.

The result is near-instantaneous AI responses, with messages coming back in under 100 milliseconds at a fraction of the power and cost of other systems.

Llama 3.1 is small, older, and far from the frontier, but Taalas says it can retool chips for new models in just months — with a top-tier option planned by winter.

The startup pulled in $169M in new funding this round, bringing its total above $200M — with a mid-size reasoning model expected this spring.

The model baked into the first chip is far from competitive, but the tech itself is the story. The speed needs to be seen to be comprehended (demo here) — and if the approach scales to frontier models, it could change what’s possible in areas like physical AI or agentic workflows where every millisecond matters.

[2/23/2026] Researchers from Meta and Google propose three layers of agentic reasoning: foundational, self-evolving, and collective – Large language models answer prompts well, but they struggle when tasks require planning, memory, and coordination across steps. A joint team from University of Illinois Urbana-Champaign, Meta, Amazon, and Google DeepMind proposes a structured framework to address this gap. The collaboration defines how to treat an LLM as an autonomous agent that plans actions, interacts with tools, updates internal state, and coordinates with other agents.

The core problem is that chain-of-thought prompting produces text, not sustained decision processes. Real systems must manage goals, execute multi-step plans, and adjust based on feedback. The researchers organize agent capability into three layers:

Foundational layer: structured planning, search, and tool execution

Self-evolving layer: memory use and feedback-driven adaptation

Collective layer: coordinated multi-agent reasoning toward shared goals

Two optimization modes: in-context structure and reinforcement-based post-training

[2/20/2026] Prompt Caching 201 – OpenAI published a detailed guide explaining how prompt caching reuses repeated prompt prefixes to skip prefill compute, reducing latency and input token costs. It outlines cache mechanics, routing considerations, KV reuse, and practical strategies for increasing cache hit rates in production workloads.

[2/20/2026] World Labs Announces New Funding – Fei-Fei Li’s start-up World Labs secured $1 billion in funding from investors like AMD, NVIDIA, and Fidelity. They aim to advance spatial intelligence with products like MARBLE, which creates cohesive 3D worlds from images, video, or text.

[2/19/2026] The quiet way AI fails at work – When AI fails at work, it usually does it quietly. According to the Connext Global 2026 AI Oversight Report, the most common issue workers see is missing context.

42% say AI leaves out important details

say AI leaves out important details 31% say it sounds confident but is wrong

Those mistakes are especially risky because they can slip past quick reviews and get acted on creating rework, escalation or customer impact downstream. In fact, 60% of workers say they’ve personally been involved in situations where AI negatively affected outcomes, and 19% say it directly made a customer situation worse. The takeaway is simple: accuracy alone isn’t enough.

[2/19/2026] Introducing Gemini 3.1 Pro: A smarter model for your most complex tasks – Today, Google is announcing a step forward in core reasoning building on the Gemini 3 series: Gemini 3.1 Pro – a noticeably smarter, more capable baseline for complex problem-solving. This is reflected in our progress on rigorous benchmarks. On ARC-AGI-2, a benchmark that evaluates a model’s ability to solve entirely new logic patterns, 3.1 Pro achieved a verified score of 77.1%. This is more than double the reasoning performance of 3 Pro.

Why it matters for enterprises: Gemini 3.1 Pro is designed to solve tougher problems, giving customers the reasoning depth their business needs. Users can bring disparate data into a single view, visualize complex topics, and solve challenges that require deep context and planning.

Starting today, Gemini 3.1 Pro is rolling out to millions of people globally:

For consumers via the Gemini app and NotebookLM

via the Gemini app and NotebookLM For enterprises in preview in Vertex AI and Gemini Enterprise.

in preview in Vertex AI and Gemini Enterprise. For developers in preview via the Gemini API in Google AI Studio, Gemini CLI, our agentic development platform Google Antigravity, and Android Studio.

[2/18/2026] Cohere’s Family of Open Models – Cohere Labs released TinyAya-Base (3.35B) and instruction-tuned TinyAya-Global plus regional variants, aiming for balanced quality across ~67 languages on consumer hardware. The drop also included a multilingual fine-tuning dataset, new benchmarks, and a technical report for reproducible multilingual experimentation.

[2/18/2026] Mistral to acquire Koyeb to build out its AI cloud stack – Mistral AI agreed to buy serverless deployment startup Koyeb in its first acquisition, positioning Koyeb’s platform and team as a core component of Mistral Compute.

[2/18/2026] Claude Sonnet 4.6 – Anthropic has released Claude Sonnet 4.6, upgrading coding, computer-use, planning, long-context reasoning, and knowledge-work performance while keeping Sonnet pricing unchanged. Sonnet 4.6 also introduced a 1M-token context window in beta and is now the default model for Free and Pro users in Claude’s apps.

[2/18/2026] Experiential Reinforcement Learning – ERL trains policies with an explicit attempt → feedback → reflection → revised attempt loop, then reinforced the successful revision back into the base model. The approach improves sparse-reward learning and tool-using reasoning performance while keeping deployment-time inference cost unchanged.

[2/17/2026] ZVEC: A lightweight, lightning-fast, in-process vector database – Alibaba’s ZVEC is an open-source, in-process vector database enabling rapid, scalable similarity searches using Alibaba’s PROXIMA engine. It supports dense and sparse vectors with hybrid searches and can be deployed across various platforms, including notebooks and edge devices. Installation is straightforward via Python or Node.js, offering a lightweight solution for handling vector data efficiently.

[2/17/2026] Qwen3.5: Towards Native Multimodal Agents – Qwen3.5-397B-A17B is the first model in the Qwen3.5 series. The native vision-language model demonstrates outstanding results in reasoning, coding, agent capabilities, and multimodal understanding. It uses an innovative hybrid architecture that fuses linear attention with a sparse mixture-of-experts. While it contains 397 billion parameters, only 17 billion are activated per forward pass. The model supports 201 languages and dialects.

[2/16/2026] The RL Architecture Behind Minimax M2.5, Explained Clearly – Minimax M2.5 is fast, cheap, and great at coding. While the team behind the model has released a technical article on how the model works, it is quite dense. This post aims to make the content of that article more accessible for readers. The core problem the team is solving is how to make RL work at massive scale for being good at Agentic AI. Training LLMs to be good at agentic tasks imposes many challenges: huge volumes of training data need to be processed quickly, training needs to be stable, and agents need to be good at a diverse range of tasks.

[2/16/2026] Reverse-Engineering the OpenAI’s GPT-5 Tokenizer – Text has to pass through a tokenizer before GPT-5.x is able to understand any input. A tokenizer is a compression layer that converts raw text into a sequence of integer IDs. Every design decision baked into the tokenizer has downstream consequences for cost, accuracy, multilingual performance, and hallucination rates. This article looks at OpenAI’s open-source tokenizer library, tiktoken, and explains how it works.

[2/16/2026] Two different tricks for fast LLM inference – Anthropic and OpenAI have unveiled new “fast modes” for LLM inference, offering differing performance enhancements. OpenAI’s model speeds exceed 1,000 tokens per second using Cerebras chips, but rely on a less capable model, while Anthropic’s fast mode supports real models with up to 2.5x speed through low-batch-size inference. Despite OpenAI’s technical achievement, the utility of faster but less capable inference remains debatable, focusing more on OpenAI’s exploration of Cerebras’ potential.

[2/16/2026] ChatGPT’s Lockdown Mode – OpenAI introduced an optional Lockdown Mode for higher-risk workflows and added “Elevated Risk” labels for capabilities in ChatGPT, ChatGPT Atlas, and Codex that can increase exposure to prompt-injection attacks.

[2/16/2026] OpenClaw creator joins OpenAI – OpenClaw’s creator will join OpenAI to develop accessible agents and ensure OpenClaw remains open and independent within a new foundation. OpenAI’s support will provide access to cutting-edge models and resources, aligning with the creator’s vision of making these tools widely usable. OpenClaw’s community will benefit from a supportive structure that encourages innovation and data ownership.

[2/13/2026] Leading Inference Providers Cut AI Costs by up to 10x With Open Source Models on NVIDIA Blackwell – Leading inference providers like Baseten, DeepInfra, and Together AI are cutting AI costs by up to 10x using open source models on NVIDIA Blackwell GPUs. In healthcare, companies like Sully.ai reduced inference expenses, improving response times and freeing up valuable time for doctors. In gaming and customer service, NVIDIA Blackwell’s optimized platforms enable Latitude and Decagon to slash token costs while enhancing user experiences and managing high workloads effectively.

[2/13/2026] Optimal Timing for Superintelligence – Essay by Nick Bostrom: Developing superintelligence is like undergoing risky surgery for a condition that would otherwise prove fatal. Some have called for a pause or permanent halt to AI development as AGI could pose existential risks. However, poorly implemented pauses could do more harm than good. The optimal strategy is to move quickly to AGI capability, then pause briefly before full development.

[2/13/2026] Gemini 3 Deep Think Upgrade – Google released a major upgrade to Gemini 3 Deep Think, its specialized reasoning mode, expanding access to Ultra subscribers and select API users. The update was developed with researchers to better handle open-ended scientific and engineering problems with messy or incomplete data.

[2/13/2026] GPT-5.3-Codex-Spark – OpenAI released GPT-5.3-Codex-Spark, a smaller ultra-fast coding model optimized for real-time use in Codex and capable of generating over 1,000 tokens per second on low-latency hardware.

[2/13/2026] Dario Amodei — “We are near the end of the exponential” – On the Dwarkesh podcast, Dario Amodei thinks we are just a few years away from “a country of geniuses in a data center.” In this episode, the discussion centers on what to make of the scaling hypothesis in the current RL regime, how AI will diffuse throughout the economy, whether Anthropic is underinvesting in compute given their timelines, how frontier labs will ever make money, whether regulation will destroy the boons of this technology, US-China competition, and much more.

[2/12/2026] $3M Grant Targets the Biggest Blind Spot in AI Benchmarks – AI agents continue to top benchmarks, yet routinely fail in real production environments. To narrow this gap, today, Snorkel AI, the Data Research Lab advancing frontier AI, announced a $3M Open Benchmarks Grant to close the evaluation gap.

This initiative funds academic and open-source teams building next-generation, open benchmarks that better reflect how agents actually operate in production. While agents continue to post impressive scores, many still struggle with long-horizon tasks, complex toolchains, noisy context, and real-world decision-making, failure modes that most benchmarks don’t meaningfully capture. The launch comes at a time when agentic systems are moving from demos into higher-stakes deployments, making evaluation a growing bottleneck. The grant reflects a broader industry shift away from leaderboard-driven progress toward benchmarks that test production realism.

[2/12/2026] Gemini Deep Think: Redefining the Future of Scientific Research – Under direction from expert mathematicians and scientists, Gemini Deep Think is solving professional research problems across mathematics, physics, and computer science.

[2/12/2026] Open Models Will Never Catch Up – Open models will probably never catch up with closed ones. However, they don’t need to – open models are an engine for exploration in a way that companies can’t really nurture. Open models are the main place where experimentation still happens. They will be the engine for the next ten years of AI research.

[2/12/2026] NVIDIA becomes first $5T company; AI chips fuel market value – NVIDIA achieved a historic milestone by briefly surpassing a $5 trillion market valuation, driven by overwhelming demand for its AI chips and dominance in data-center accelerators. Its advanced Blackwell and Rubin GPU platforms power the bulk of large-model training and inference workloads, underpinning investor confidence in continued AI infrastructure growth. This valuation reflects NVIDIA’s central role in the AI economy and illustrates how hardware leadership translates to extraordinary market value.

[2/12/2026] How Codex Built an Internal Product – OpenAI described an internal experiment where a small team shipped a product whose codebase—app logic, tests, CI, docs, and tooling—was generated entirely by Codex agents rather than written by humans.

[2/12/2026] GLM-5: From Vibe Coding to Agentic Engineering – GLM-5 is a new MIT-licensed model with 754 billion parameters. It delivers significant improvement compared to GLM-4.7 across a wide range of academic benchmarks and achieves best-in-class performance among all open-source models on reasoning, coding, and agentic tasks. GLM-5 is designed for complex systems engineering and long-horizon agentic tasks. It has been open-sourced on Hugging Face and ModelScope and can be tried for free on Z.ai.

[2/11/2026] Kimi Introduces Agent Swarm: Let 100 AI Agents Work for You – Kimi Agent Swarm is an AI CEO who helps find researchers, analysts, and fact-checkers without micromanagement. It builds an organizational structure with bosses, employees, and divisions of labor by itself. Agent Swarm excels where work can be parallelized, like broad research, batch downloads, multi-file processing, multi-angle analysis, and long-form writing. It creates the conditions for productive disagreement to avoid groupthink structurally. Agent Swarm is now available to Kimi Top Tier subscribers in early research preview.

[2/11/2026] WarpGrep: Fast Context RL Retrieval – WarpGrep is a lightweight RL‑trained retrieval sub‑agent that finds the exact code files and line ranges developers need up to 5× faster than standard models by limiting search to four turns of parallel grep/read/glob calls. This approach keeps the main LLM’s context clean, cuts noise, and halves token usage by specializing retrieval, not reasoning. In benchmarks on large repositories, WarpGrep doubled precision and maintained ~5‑second search times while reducing irrelevant context pollution.

[2/11/2026] America’s $1T AI Gamble – The US economy is buoyed by the AI boom, but nowhere near entirely driven by it. The tech industry’s investments in AI have to pay off if they hope to accelerate American growth. Most AI companies still have massive spending capabilities from their other profitable digital ventures, and investors can be easily tapped for additional money at extremely high valuations. There are no signs of the American AI boom slowing down.

[2/11/2026] Musk’s xAI loses second co-founder in two days – xAI co-founder Tony Wu announced his exit from the company on Monday, then fellow co-founder and influential researcher Jimmy Ba announced his departure from the company the next day. Other co-founders, including Igor Babuschkin, Kyle Kosic, and Christian Szegedy, have also departed the company. Elon Musk launched xAI alongside 11 other people in 2023. The company was merged with Musk’s aerospace company, SpaceX, earlier this month.

[2/10/2026] Reinforcement World Model Learning for LLM Agents – RWML is a self-supervised method that helps LLMs better simulate environment dynamics. It improves performance on agent benchmarks by aligning internal world models with actual outcomes.

[2/10/2026] The Potential of RLMs – Recursive Language Models (RLMs) can mitigate the effects of context rot. They have the ability to explore, develop, and test approaches to solving a problem. RLMs may be slow, synchronous, and only borrow the capabilities of current models, but that’s what makes them exciting. Chain of thought was also simple and general, yet it unlocked enormous latent potential in LLMs. Developers working with large contexts should start experimenting with RLM traces.

[2/10/2026] The many masks LLMs wear – There is evidence that large language models can attempt to evade oversight and assert control. Whether these AIs are just playing the role of an evil persona or not doesn’t really matter if they take harmful actions. Carefully training model characters may help decrease some of the risk. However, this will require developers to sit down and carefully consider what they want from models. These decisions could dictate how future AIs treat humans.

[2/9/2026] AI agent adoption grew in 2025, but 40% of work is still reviewed by humans – DigitalOcean, the inference cloud platform, today released findings from a survey of developers who are shaping the shift toward inference and agents. As companies move toward agentic adoption, the report offers a look at the current state of affairs:

Agentic use is growing: The rate of companies implementing and optimizing AI as a core business strategy grew to 52% from 35% in 2024.

The rate of companies implementing and optimizing AI as a core business strategy grew to 52% from 35% in 2024. AI agents save time : Productivity gains are on the rise, with 53% of respondents reporting saved time from the use of agents.

: Productivity gains are on the rise, with 53% of respondents reporting saved time from the use of agents. Humans are still a must: Only 10% reported having fully autonomous agents, and 40% said that humans still review agentic work.

Only 10% reported having fully autonomous agents, and 40% said that humans still review agentic work. AI spending is shifting toward inference: Almost half of respondents said that a supermajority of their budget will now go toward AI inferencing (the use of AI to make predictions or decisions) over AI training.

Almost half of respondents said that a supermajority of their budget will now go toward AI inferencing (the use of AI to make predictions or decisions) over AI training. Infrastructure as an essential strategy: Most organizations (60%) are using multiple tools stitched together, or a hybrid of multiple tools alongside an integrated stack to support workflow efficiencies and scalability.

DigitalOcean’s pulse check on the developer ecosystem is a clear way to understand where agentic AI is headed next, including what tools and infrastructure enterprises will need to move toward inference. Expect to see the expansion of AI agents in 2026, as 38% of respondents who haven’t yet explored agents report that they will start exploring or deploying agents at that time.Coupled with recent company announcements about its partnership with Character.ai and AMD and its launch of one-click deployment for OpenClaw, the survey offers proof points that companies are accelerating their use of AI deployment.

[2/9/2026] OpenAI CEO Altman dismisses Moltbook – Sam Altman said at the Cisco AI Summit in San Francisco that the viral AI driven social network Moltbook is likely a short lived fad, but emphasized that the underlying technology enabling autonomous AI agents is a meaningful sign of where computing is headed.

While downplaying the Reddit like platform itself, Altman noted that bots acting independently and interacting with each other highlight rapid progress toward more human like machine behavior, fueling broader debate about how close artificial intelligence is to genuine autonomy and intelligence.

[2/9/2026] OpenAI’s Frontier to manage “AI coworkers” – OpenAI just launched Frontier, a new platform for enterprises to deploy and manage AI agents like new hires — complete with onboarding, permissions, and performance reviews across a company’s existing tech stack.

Key details:

Frontier connects to existing enterprise systems like CRMs and ticketing tools, letting agents pull context from across the business without migrations.

Built-in eval and feedback loops let agents learn via experience, with OAI comparing it to onboarding a new employee with reviews and boundaries.

Every agent operates under its own profile with scoped access and hard limits on what it can touch for enterprise and regulated control.

HP, Oracle, State Farm, and Uber are among the first adopters, with OAI embedding engineers on-site to help teams get agents into production.

Anthropic and OAI have been battling over models and coding tools, but Frontier shows the fight is also bleeding into who controls the enterprise agent layer underneath. Model capabilities are making AI coworkers a reality in the near future, and the system that ultimately orchestrates them will be valuable real estate.

[2/9/2026] Tesla and Waymo testify about self-driving cars – At a Senate Commerce Committee hearing featuring executives from Tesla and Waymo, lawmakers expressed strong optimism about the future of autonomous vehicles in the US and signaled interest in modernizing federal regulations to improve safety, build public trust, and compete with China, even as public skepticism remains high.

Industry leaders urged Congress to establish a national framework enforced by National Highway Traffic Safety Administration. The hearing highlighted tension between rapid industry progress and limited regulatory capacity, concerns over staffing cuts at NHTSA, and the challenge of winning over a public that largely distrusts self driving cars, even as Waymo reported its autonomous vehicles are involved in fewer crashes than human drivers and already deliver hundreds of thousands of rides each week.

[2/6/2026] Anthropic releases Claude Opus 4.6 adding agent teams, 1M token context, and new effort controls – Claude Opus 4.6 enters as Anthropic’s new top-tier model, built for a familiar problem: AI systems break down when tasks get long, messy, and codebases get big. As agents run longer, context drifts, reasoning degrades, and developers intervene. Opus 4.6 targets that failure mode directly, with deeper planning, longer memory, and stronger agentic execution.

At the center of the release is scale. Opus 4.6 is the first Opus-class model with a 1M token context window, which means you can keep entire repositories, long documents, or extended agent runs in memory without constant truncation. Anthropic pairs that with new controls so you decide how much reasoning the model uses and how long it runs.

Key details:

1M token context (beta) for long-running agents and large-codebase analysis

128k output tokens for single-pass generation of large artifacts

Adaptive thinking so the model decides when deeper reasoning is necessary

Effort levels (low to max) to trade latency and cost against reasoning depth

Context compaction that summarizes old turns to extend agent runtime76% on MRCR v2 (1M, 8-needle) for long-context retrieval

+144 Elo vs GPT-5.2 and +190 Elo vs Opus 4.5 on GDPval-AA

You can use Opus 4.6 via claude-opus-4-6 in the API, Claude Code agent teams, or Claude’s document and spreadsheet tools for long, structured workflows.

[2/5/2026] The Q, K, V Matrices – At the core of the attention mechanism in LLMs are three matrices: Query, Key, and Value. These matrices are how transformers actually pay attention to different parts of the input. This write-up goes through the construction of these matrices from the ground up.

[2/5/2026] Why NVIDIA builds open models with Bryan Catanzaro – NVIDIA’s focus on building open models, spearheaded by efforts like the Nemotron 3 Nano release, positions it uniquely to enhance both its product offerings and the AI ecosystem. Open model development aids NVIDIA in understanding compute-heavy AI workloads, which informs their hardware and software design, while fostering greater community collaboration. NVIDIA distinguishes itself by emphasizing open data and models to drive AI infrastructure, benefiting businesses without AI acting as an overarching monopolistic event.

[2/5/2026] Impulse AI launches no-code autonomous machine learning platform – The platform automates data prep, model training, deployment and monitoring and recently ranked in the top 2.5% of a Kaggle competition. Impulse AI announced the launch of its autonomous machine learning platform that enables teams to build, deploy, and monitor production-grade AI models without writing code or hiring specialized ML engineers. The company’s AI agent recently validated its capabilities by placing in the top 2.5% (rank 782 out of 31,791 participants) in a featured Kaggle competition, demonstrating performance that matches or exceeds human ML engineers.

[2/5/2026] Introducing GPT-5.3-Codex – Expanding Codex across the full spectrum of professional work on a computer. OpenAI is introducing a new model that unlocks even more of what Codex can do: GPT‑5.3-Codex, the most capable agentic coding model to date. The model advances both the frontier coding performance of GPT‑5.2-Codex and the reasoning and professional knowledge capabilities of GPT‑5.2, together in one model, which is also 25% faster. This enables it to take on long-running tasks that involve research, tool use, and complex execution. Much like a colleague, you can steer and interact with GPT‑5.3-Codex while it’s working, without losing context.

[2/5/2026] Mistral AI releases Voxtral Transcribe 2 with sub-200 ms realtime transcription and open weights for Voxtral Realtime – Mistral AI introduces Voxtral Transcribe 2 at a time when speech-to-text systems struggle with either latency or cost. Most models trade real-time speed for accuracy or lock strong performance behind high prices.

Voxtral Transcribe 2 targets both problems with a split design: one model for batch jobs and one built from the ground up for live audio. The key shift is a native streaming architecture that transcribes audio as it arrives, not after chunks accumulate. Voxtral Transcribe 2 solves two common workflows: large-scale transcription and low-latency voice interaction. Batch users process long recordings cheaply, while realtime users power voice agents and live captions without long delays. You access both through API or test them in Mistral Studio.

Key details:

Voxtral Mini Transcribe 2 handles batch transcription and long audio workloads.

Voxtral Realtime processes live audio with configurable sub-200 ms latency.

Speaker diarization labels who speaks and when in multi-speaker audio.

Context biasing steers decoding toward correct names or technical terms.

Word-level timestamps align text precisely with audio.

Mini reports ~4% WER on the FLEURS benchmark.

Realtime stays within 1–2% WER of offline at 480 ms delay.

Pricing starts at $0.003 per minute for batch and $0.006 per minute realtime.

Realtime weights ship under Apache 2.0 for local or edge deployment.

[2/4/2026] Adaption raises $50M in seed funding – Everything intelligent adapts. So should AI. That’s why, the company is announcing its $50 million seed to make AI adaptive. Today’s AI is expensive, static, and slow to change. A handful of companies today build one-size-fits-all-models, built to optimize for the average. They’re shaped by a narrow slice of the world’s languages, cultures, and problems deemed mainstream. Averages erase the exceptional. When AI can’t adapt in real time, the most impactful use cases are left behind.

[2/4/2026] Hierarchical memory management in agent harnesses – Go deeper into the emerging best practices for agent memory design and learn how the lessons of the last 50 years of computing are still relevant.

[2/4/2026] Alibaba’s Qwen introduces Qwen3-Coder-Next, an open-weight coding agent model with 80B parameters – Alibaba’s Qwen team releases Qwen3-Coder-Next to answer a practical problem many teams hit: strong coding agents cost too much to run locally. Most agentic coding models grow by adding parameters. This one takes a different path and scales training signals instead.

The standout detail is efficiency: the model holds 80B total parameters but activates only 3B at inference, which cuts compute while keeping agent performance high. At its core, Qwen3-Coder-Next is an open-weight model built for multi-step coding agents. It uses Mixture-of-Experts, which means the model selects a few specialist subnetworks per token instead of using everything at once. It also trains on 800K executable coding tasks, so the model learns from code that actually runs and fails.

Key details:

Hybrid attention plus MoE architecture with 3B active parameters

Agentic training with executable environments and reinforcement learning

Open-weight release for local and self-hosted setups

Over 70% on SWE-Bench Verified with SWE-Agent

Competitive SWE-Bench Pro scores versus models with 10–20× active parameters

Plug into OpenClaw, Cline, Claude Code, or browser-based agents

Run locally with MoE-capable inference stacks

Use for multi-step debugging, refactors, and tool-driven coding workflows

[2/3/2026] State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI – From the Lex Fridman podcast, Nathan Lambert and Sebastian Raschka are machine learning researchers, engineers, and educators. Nathan is the post-training lead at the Allen Institute for AI (Ai2) and the author of The RLHF Book. Sebastian Raschka is the author of Build a Large Language Model (From Scratch) and Build a Reasoning Model (From Scratch).

[2/3/2026] Introducing SERA—Open coding agents you can customize – It’s been a big month for open, customizable coding models. We’re excited to share Ai2 Open Coding Agents, starting with SERA by Ai2—a family of open models and an efficient training recipe that makes it practical to specialize a coding agent to any repo, including private codebases.

Closed coding agents don’t know your internal APIs, conventions, or tooling. With SERA, you can generate realistic, agent-style training data from a repo and fine-tune quickly—so the agent learns how your codebase actually works. If you’re a small to mid-sized business or independent developer working with customer data in ways no public model has ever seen, SERA lets you specialize a model to your stack without exposing that data to an outside provider.

The key insight behind SERA is that high-quality synthetic training data should mirror how a developer works on a problem rather than the precise details of correct code. Combined with our soft-verification approach, this makes it straightforward to generate massive amounts of agentic training data for any codebase—so a repo with thousands of functions can yield tens of thousands of varied trajectories at low cost.

One result we’re especially excited about: a smaller, open model can replicate and even exceed the performance of a more capable “teacher” coding agent when specialized to a particular codebase. This means you can compress frontier-level performance into a small, easily deployable model tailored to your private data.

We believe bringing the cost of replicating strong coding agents down to a few hundred dollars will unlock research that simply wasn’t possible before. Instead of being limited to a handful of well-funded labs, agentic coding can become a widely accessible practice. Case in point: SERA was built largely by a single Ai2 researcher. Read the technical report HERE.

[2/2/2026] Does AI already have human-level intelligence? The evidence is clear – The vision of human-level machine intelligence laid out by Alan Turing in the 1950s is now a reality. Eyes unclouded by dread or hype will help us to prepare for what comes next.

[2/2/2026] Most data problems are people problems in disguise: unclear definitions, conflicting goals, or lack of domain context. Before debugging your model, make sure everyone agrees on what “success” looks like.

[2/2/2026] Ai2 introduces Theorizer, providing open-source code for automatic theory synthesis from scientific papers – Researchers already automate experiments, but they still read hundreds of papers to extract laws. Theorizer flips that workflow by reading the literature first and writing theories directly. The striking part: it synthesizes explicit scientific laws from up to 100 papers per query. The system treats a theory as compressed knowledge. A law states a repeatable pattern, scope states where that pattern holds, and evidence cites results from real papers. You can think of it as a map from scattered findings to testable claims. You use Theorizer by entering a topic query. The system retrieves open-access papers, extracts structured results, and assembles theories with linked evidence.

Key details:

Reads and processes up to 100 papers per query

Outputs ⟨LAW, SCOPE, EVIDENCE⟩ instead of summaries

Uses GPT-4.1 for theory synthesis and GPT-5 mini for extraction

Runs in 15–30 minutes per query

Evaluates 2,983 laws against 4,554 papers

Achieves 0.88–0.90 precision in accuracy-focused tests

Improves recall from 0.45 to 0.51 with literature grounding

[2/2/2026] Anthropic study shows AI help speeds tasks but significantly harms short-term conceptual understanding – A new randomized controlled trial by Anthropic examines what happens to coding skills when AI writes code during learning. The study focuses on developers learning Trio, a Python library for asynchronous programming, with or without AI assistance.

The most striking finding shows a large drop in short-term mastery while task speed barely changes. Anthropic designs the study to mirror real workplace learning. Fifty-two software engineers who use Python weekly but have no Trio experience complete guided coding tasks, then take a quiz minutes later. One group uses an AI assistant with full access to their code. The control group codes by hand.

What Anthropic evaluates:

Learning speed while implementing unfamiliar async programming patterns

Short-term understanding measured immediately after task completion

Debugging, code reading, and conceptual comprehension

What the results show:

AI group averages 50% on the quiz; no-AI group averages 67%

The difference equals 17 percentage points (Cohen’s d 0.738, p 0.01)

Debugging questions show the largest performance gap

AI users finish about two minutes faster, without statistical significance

[1/30/2026] How are Stanford students using GenAI? – The use of AI in schoolwork has become as ubiquitous as using Google. Many professors now include a statement on GenAI usage or over-reliance in their syllabi for courses. But a larger question remains: How are students actually using AI? Here is an article appearing in the Stanford Daily campus newspaper.

[2/2/2026] Darren Aronofsky debuts AI Revolutionary War series – Filmmaker Darren Aronofsky’s AI venture Primordial Soup released “On This Day… 1776”, a new series recreating the American Revolution using Google DeepMind, with each episode dropping on the 250th anniversary of the event it depicts.

Key details:

The short-form series combines AI-generated visuals with SAG-AFTRA voice actors, positioning itself as “artist-led” AI rather than being fully automated.

The series drops episodes on TIME’s YouTube channel timed to the 250th anniversary of each depicted event.

Aronofsky partnered with DeepMind in May to collaborate on AI storytelling, releasing the Veo-assisted film ANCESTRA in June at the Tribeca Film Festival.

AI video is creeping further into real production studio workflows, and moving from simple shorts and hidden tricks to hide faces to handling the entire visual process. While it still might not be fully accepted or mainstream, the sentiment is shifting — and Hollywood’s once-uneasy use of the tech is coming more into focus.

---

*Content scraped from public sources with attribution. Users assume all risk.*  
*Auto-generated by [Perplexity News Tracker](https://github.com/myidkd1-coder/perplexity-news-tracker)*